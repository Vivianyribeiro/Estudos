CAPÍTULO 25
 	Usando Agentes de Software Autônomos em Sistemas de Apoio à Decisão, Loren Paul Rees2 e Terry R. Rakes2 1 Departamento de Sistemas de Informação, College of Business, Washington State University, Pullman, WA EUA 2 Departamento de Tecnologia da Informação Empresarial, Pamplin College of Business, Virginia Polytechnic Institute and State University, Blacksburgh, VA, EUA 

O objetivo desta pesquisa é definir agentes de software autônomos e descrever uma estrutura geral para o uso de agentes no suporte à decisão sistemas (DSS). Como as definições de agentes de software existentes na literatura são divergentes, desenvolvemos e fornecemos uma definição descritiva útil para nosso propósito. Os benefícios dos agentes e as características particulares dos agentes que levam ao enriquecimento de DSS são examinados. Para facilitar isso, construímos um DSS, descrito em outra parte da literatura, e o aprimoramos com diferentes tipos de agentes de software autônomos. A partir dessa experiência, é sugerida uma estrutura geral para DSS habilitado para agente. 

Palavras-chave: Inteligência artificial; Sistemas autônomos; Sistemas de Suporte à Decisão; Agentes de software

 1 Introdução 

	Em 1997, a IBM previu que os agentes de software (programas que executam tarefas em nome de um usuário) se tornariam um dos paradigmas de computação mais importantes (Gilbert 1997). Organismos de definição de padrões foram formados para abordar as questões de comunicação e mobilidade do agente (Chang e Lange 1996; Neches et al. 1991), e vários kits de ferramentas do agente foram produzidos (Serenko e Detlor 2003) para apoiar o desenvolvimento e uso de agentes habilitados para Programas. O número de aplicativos de agentes comerciais e de pesquisa que foram implementados desde então fornece evidências de que a indústria de computação reconheceu o potencial desse paradigma e investiu em tecnologia habilitada para agentes (Huhns e Singh 1998; Hess et al. 2005; Nissen e Sengupta 2006). Os pesquisadores e desenvolvedores do sistema de suporte à decisão (DSS) também foram rápidos em empregar agentes dentro do DSS. 

* A versão original deste artigo foi publicada pelo Decision Sciences Institute, localizado na Georgia State University em Atlanta, GA. www.decisionsciences.org. (Hess, TJ, Rees, LP e Rakes, TR “Using Software Agents to Create the Next Generation of Decision Support Systems,” Decision Sciences, 31(1), 2000, 1–31).

 	O conceito básico e a implementação de um agente de software, no entanto, ainda varia muito em uma ampla gama de implementações de agentes (Jennings et al. 1998). O objetivo geral deste documento é fornecer uma definição descritiva de agentes de software no domínio do DSS e fornecer orientação para desenvolvedores de DSS que buscam habilitar seus aplicativos como agentes. Primeiro descrevemos o estado geral do desenvolvimento do DSS e das implementações de agente de software dentro do DSS. 

1.1 Uma visão geral dos sistemas de apoio à decisão 

	O fluxo de pesquisa DSS originou-se há mais de 30 anos e foi fornecido com uma base sólida para pesquisa e desenvolvimento contínuos pelos trabalhos de Keen e Scott Morton (1978), Bonczek, Holsapple e Whinston (1980). Sprague e Carlson (1982), Bennett (1983) e outros. DSS fornecem suporte para decisões semiestruturadas e não estruturadas, e representam um campo multidisciplinar composto por pesquisadores de sistemas de informação gerencial (MIS), pesquisa operacional, inteligência artificial (IA), estudos organizacionais e outros. Avanços tecnológicos e avanços de pesquisa em outras disciplinas foram rapidamente adotados dentro dos componentes individuais ou subsistemas do DSS, ou seja, o sistema de gerenciamento de geração de diálogo (DGMS), o sistema de gerenciamento de banco de dados (DBMS) e o sistema de gerenciamento de base de modelo (MBMS) ( Sprague e Carlson 1982). Na última década, dentro do DGMS, as interfaces melhoraram substancialmente em aparência e usabilidade por meio do uso de ambientes de desenvolvimento de programação visual. Da mesma forma, a interoperabilidade e o conteúdo do componente DBMS foram aprimorados por meio de padrões de conectividade de banco de dados (ODBC, OLE DB, JDBC, ADO.NET, etc.), armazenamento de dados e acesso a dados baseado na Web. O MBMS, no entanto, é considerado o componente menos desenvolvido e é o foco de grande parte da pesquisa atual em DSS. A combinação de gerenciamento de modelos e inteligência artificial é essencial para fornecer suporte à decisão e é vista como a pedra angular de DSS mais avançados (Radermacher 1994; Barkhi et al. 2005).

 1.2 O uso de agentes de software em um DSS
	 Dada a história da inteligência artificial na pesquisa de DSS e os interesses atuais em integrar ainda mais as técnicas de IA em DSS, não surpreende que os pesquisadores de DSS tenham reconhecido rapidamente a promessa de empregar agentes de software em DSS. As contribuições potenciais de agentes de software para DSS foram descritas como enormes (Whinston 1997), e as implementações de DSS que utilizam programas semelhantes a agentes (Elofson et al. 1997; Maturana e Norrie 1997; Oliver 1996; Pinson e outros. 1997) e comunidades de agentes (Kishore et al. 2004; Shaw et al. 2002, Liang e Huang 2000) apareceram em vários periódicos. Devido à natureza subjetiva da agência e à ampla variedade de contextos e disciplinas em que programas semelhantes a agentes foram implantados, uma definição ou descrição geral de agentes não existe na literatura DSS/MIS . Essa dificuldade em descrever o que é um agente resultou no uso excessivo do termo “agente” e em uma orientação inadequada para desenvolvedores de DSS que buscam habilitar seus aplicativos para agentes. Embora os pesquisadores do DSS tenham discutido os agentes como um meio para integrar várias capacidades no DSS e para coordenar o uso efetivo da informação (Kishore et al. 2006; Whinston 1997; Elofson et al. 1997), tem havido pouca discussão sobre por que essas entidades são adequadas para tais tarefas. 
	O propósito desta pesquisa é (1) desenvolver uma definição útil de agentes de software; (2) para fornecer um exemplo de um DSS ativado por agente (fornecemos uma extensão de um DSS relatado por Holsapple e Whinston (1996) que foi aprimorado com vários tipos diferentes de agentes); (3) demonstrar os benefícios obtidos com o uso de agentes no DSS; e (4) usar a visão obtida da construção do DSS para sugerir uma estrutura geral para integrar agentes de software no DSS. Também comentamos sobre o esforço adicional necessário para adicionar agentes ao DSS.
	 Este capítulo está organizado da seguinte forma. A Seção 2 desenvolve uma definição de um agente de software autônomo. Na Seção 3, descrevemos o DSS habilitado para agente, fornecendo mais informações sobre os recursos essenciais e capacitadores do agente. Os benefícios gerais do uso de agentes são descritos na Seção 4, juntamente com os benefícios específicos obtidos em nossa implementação do DSS integrado ao agente. Na Seção 5, desenvolvemos uma estrutura geral para a construção de DSS habilitados para agentes. Por fim, a última seção contém as conclusões e limitações.

>> 2 Definição de Agente de Software

O termo "agente" significa coisas diferentes para diferentes autores e muitas definições não são explicitamente enunciadas. Quando colocadas lado a lado, as definições de agentes de software na literatura podem ser conflitantes e desconcertantes, e ainda não foram resolvidas (Franklin e Graesser 1996; Nissen e Sengupta 2006). Implementações de agentes baseados na teoria da sociedade da mente de Minsky (Minsky 1985) consideram processos simples como agentes (Riecken 1997; Boy 1997); por exemplo, um procedimento que destaca uma imagem quando o mouse é movido sobre o texto relacionado é considerado um agente. Por outro lado, pesquisas de agentes no outro extremo do espectro descartam esse ponto de vista e sugerem que os agentes são assistentes avançados de computação (Maes 1994; Negroponte 1997). Mas mesmo dentro de um ponto de vista particular, ainda pode haver confusão e imprecisão na terminologia. Imam e Kodratoff (1997, p. 75) apontaram que "se um pesquisador ou qualquer pessoa curiosa quisesse aprender sobre agentes inteligentes, ele/ela poderia ficar confuso(a) depois de ler apenas alguns artigos...". Vários pesquisadores afirmam qualidades abstratas, como autonomia, inteligência ou capacidade de solução de problemas, como características definidoras de um agente. Mas, como Covigaru e Lindsay (1991) observaram em sua discussão sobre criaturas inteligentes e sistemas autônomos, há relacionamentos entre esses (e termos similares) usados na literatura. Cada um não pode ser a "propriedade-chave".

Acreditamos que essas dificuldades de definição surgiram por duas razões principais: falha em fornecer explicitamente um ponto de referência na definição de agente e falha em diferenciar características essenciais (ou seja, definidoras) de agentes de características capacitadoras. Tentaremos desenredar esses problemas de maneira geral, mas observamos que implicitamente na abordagem que adotamos está o acordo tácito com a literatura de que os agentes de software devem ser descritos (por exemplo, por meio de listas de atributos) se o progresso na definição for ser feito (Bradshaw 1997). (É interessante observar que esta é a mesma abordagem seguida com os SAD em seus primeiros dias. Veja, por exemplo, Alter (1980, Capítulo 2) e seus sete tipos de SAD.) Uma lista geral de atributos de agentes de software frequentemente mencionados ou implícitos nas definições literárias é a seguinte: autonomia, orientação a objetivos, persistência, reatividade, mobilidade, inteligência e interatividade.

	2.1 Resolvendo Problemas de Definição
O primeiro passo antes de examinar a lista de atributos é rejeitar o ponto de vista da sociedade da mente de Minsky em favor da noção de agentes como descritos por Maes (1994) e Negroponte (1997), ou seja, como "assistentes avançados de computação". Fazemos isso porque acreditamos que a última noção será mais útil no campo de SAD. Também acreditamos que a maioria dos profissionais, estejam ou não na área de SAD, não consideram os movimentos do mouse com o propósito de destacar imagens como um comportamento definidor de agentes.

		2.1.1 Ponto de Referência
 Com a distinção acima em mente, um agente é um representante, um substituto ou um substituto para outro. Para definir um agente de forma significativa, deve-se especificar (1) quem o agente está representando (o empregador do agente), (2) a tarefa a ser realizada e (3) o domínio da tarefa (ver Figura 1). Observe que a falha em estipular todos os três itens como ponto de referência pode levar a confusão. Por exemplo, apenas afirmar que o jogador de basquete Michael Jordan tinha um agente não define esse agente de maneira útil. Se afirmarmos que o domínio do agente era negociações salariais com a National Basketball Association, e que a tarefa era obter e manter as condições econômicas mais favoráveis ​​para o empregador do agente (ou seja, Michael Jordan), então reconhecemos que o agente o representou nas negociações salariais, mas não se esperava que o substituísse durante os jogos de basquete. Além disso, notamos que diferentes agentes executarão tarefas amplamente diferentes. Por exemplo, para ser bem-sucedido, seu agente de seguros de automóveis precisará fazer trabalhos diferentes dos do agente assalariado de Michael Jordan e de um agente de software. Como consequência, diferentes agentes terão valores diferentes dos atributos listados acima.
		 2.1.2 Diferenciação 
Conforme sugerido, a abordagem de definição utilizada aqui é gerar um subconjunto de atributos dos sete encontrados na literatura, listados acima; a esperança é encontrar dois ou três termos essenciais que, juntos, descrevam de maneira útil e distinta um agente de software. A próxima etapa ao prosseguir com a lista de atributos é redirecionar nosso foco para o objetivo de definir um agente de software autônomo. Fazemos isso porque a literatura indica, como será visto, que a autonomia está na própria essência do comportamento humano e, portanto, do agente e, portanto, é um termo mais abrangente do que o outro seis características.

Figura 1. O empoderamento de um agente de software 

	Wooldridge e Jennings (1995) afirmaram que uma característica essencial para programas projetados para agir como um agente é que eles sejam capazes de “operar sem a intervenção direta de humanos ou outros, e ter algum tipo de controle sobre suas ações e processos internos”. estado” (pág. 4). Eles definiram essa característica como autonomia. Essa característica fundamental do agente é definida de forma semelhante por vários outros pesquisadores de agentes (Nwana 1996; Franklin e Graesser 1996; Gilbert 1997) e está de acordo com a definição do dicionário Merriam-Webster (2006) do termo autônomo de uma perspectiva humana, como “a qualidade ou estado de ser autogovernado”. Se a essência de um agente é ser um representante e/ou um substituto, então certamente um agente deve fazê-lo de forma independente, ou seja, sem ter que consultar repetidamente o agente empregador para obter ajuda ou instruções. Isso certamente seria verdade na arena do DSS: não se deve esperar que os usuários forneçam ajuda e instruções repetidamente aos agentes do DSS que deveriam ajudá-los.
	 Parte da busca para encontrar uma definição de agentes é determinar o(s) atributo(s) humanoide(s) que os agentes devem possuir quando se tornam substitutos ou representantes de humanos. Isso se deve ao fato de que, embora os agentes possam ser representantes de outros agentes, em última análise, alguns agentes de nível superior serão agentes para humanos. (No software, os agentes geralmente atendem aos usuários, que são humanos.) Em seu artigo sobre sistemas semelhantes aos humanos, Covrigaru e Lindsay (1991) concluíram que a essência dos sistemas semelhantes aos humanos é a autonomia. Eles decidem que a essência do comportamento humano não é a solução de problemas per se, como se supunha nos primeiros dias da inteligência artificial. Em vez disso, eles estipularam que uma entidade deve ser autônoma para ser verdadeiramente inteligente, verdadeiramente viva e verdadeiramente humanóide. Autonomia é a característica que permite que humanos e sistemas humanóides atuem como assistentes. Covrigaru e Lindsay (1991) desenvolveram ainda mais a ideia de que vários outros atributos da literatura que listamos são componentes de uma definição de autonomia. O termo autonomia é, portanto, abrangente; inclui conceitos como orientação para objetivos. 

 	Voltaremos nossa atenção à busca de outros atributos para listar como componentes essenciais para nossa definição, mas agora nossa tarefa é definir um agente autônomo. A literatura, infelizmente, dá apenas suporte parcial, e teremos que recorrer, em última análise, à lógica e ao bom senso. Covrigaru e Lindsay (1991) argumentaram que a essência da autonomia é que a entidade ou sistema deve estar tentando realizar algo, ou seja, deve ser direcionado a um objetivo. As rochas, por exemplo, não perseguem objetivos e, portanto, são candidatos improváveis ​​a se tornarem agentes. Como a literatura não fornece mais orientações substantivas sobre quais recursos são essenciais e quais não são, agora damos uma olhada no "senso comum" para definir um agente autônomo, começando com o ponto de referência dado na Figura 1. 
	Como sugere a parte esquerda da Figura 1, alguém ou algo “contrata” ou emprega um agente para realizar uma tarefa em um determinado domínio. Um meio possível de especificar a tarefa é declarar os objetivos da tarefa. Observando os outros termos da nossa lista de atributos do agente, nem sempre é essencial que o agente seja móvel porque muitas tarefas do agente podem ser executadas em um local. Além disso, não é essencial que o agente possua inteligência, pelo menos no sentido do termo IA, porque muitas tarefas exigem apenas ação e não muito raciocínio ou capacidade inferencial. Da mesma forma, a interatividade (ou seja, a capacidade de interagir e se comunicar com outras pessoas) não é essencial para todas as tarefas. Por exemplo, o agente empregado para cortar minha grama não precisa ser particularmente inteligente ou um grande comunicador. No entanto, um agente deve possuir uma capacidade de reagir no domínio em algum nível fundamental, e o agente deve persistir por tempo suficiente para atingir os objetivos do empregador. Assim, concluímos que um agente deve possuir orientação para o objetivo, persistência e reatividade. Embora inteligência, mobilidade e interatividade possam aprimorar as capacidades de um agente, elas não são características essenciais. Assim, a lista de características essenciais é orientação para objetivos, persistência e reatividade. Novamente, observe que para um determinado agente, cada característica é definida em termos de um ponto de referência. Assim como os agentes humanos diferem em persistência, não ficaremos surpresos ao ver alguns agentes de software persistirem por milissegundos, enquanto outros persistirão por semanas. O requisito é que o agente resista o tempo suficiente para concluir a tarefa especificada no domínio especificado. 
	Os recursos restantes em nossa lista inicial de sete – inteligência, mobilidade e interatividade – compõem a lista de recursos de capacitação do agente. O uso de um ou mais desses recursos de capacitação pode aumentar significativamente a utilidade de um agente autônomo, mas, conforme observado anteriormente, esses recursos não são considerados essenciais. Tanto os atributos essenciais quanto os de capacitação do agente foram discutidos de forma um tanto vaga até este ponto. Agora fornecemos nossa definição/descrição de um agente de software autônomo, que é seguido por uma elaboração da terminologia de atributo. e interatividade – compõem a lista de recursos do agente capacitador. O uso de um ou mais desses recursos de capacitação pode aumentar significativamente a utilidade de um agente autônomo, mas, conforme observado anteriormente, esses recursos não são considerados essenciais. Tanto os atributos essenciais quanto os de capacitação do agente foram discutidos de forma um tanto vaga até este ponto. Agora fornecemos nossa definição/descrição de um agente de software autônomo, que é seguido por uma elaboração da terminologia de atributo. e interatividade – compõem a lista de recursos do agente capacitador. O uso de um ou mais desses recursos de capacitação pode aumentar significativamente a utilidade de um agente autônomo, mas, conforme observado anteriormente, esses recursos não são considerados essenciais. Tanto os atributos essenciais quanto os de capacitação do agente foram discutidos de forma um tanto vaga até este ponto. Agora fornecemos nossa definição/descrição de um agente de software autônomo, que é seguido por uma elaboração da terminologia de atributo.


	2.2 Nossa definição
 Um agente de software autônomo é uma implementação de software de uma tarefa em um domínio especificado em nome ou no lugar de um indivíduo ou outro agente. A implementação conterá meta(s) homeostática(s), persistência e reatividade na medida em que a implementação (1) persistirá por tempo suficiente para realizar a(s) meta(s) e (2) irá reagir suficientemente dentro de seu domínio para permitir que o(s) objetivo(s) seja(m) alcançado(s) e saber desse fato. Observe as seguintes questões com relação a esta definição: 
		2.2.1 Objetivo(s) homeostático(s) 
	É difícil imaginar um assistente pessoal ou agente que trabalhe de forma independente, tendo algum tipo de controle sobre suas ações e estado interno, mas não tenha um objetivo . Um agente sem um objetivo, alguma responsabilidade ou tarefa atribuída, não presta assistência ao utente e não tem meios para agir de forma autónoma porque não tem ato a realizar. 

Uma visão mais forte da característica orientada a objetivos sustenta que uma entidade autônoma deve fazer mais do que apenas atingir um objetivo e então parar de funcionar. Em vez disso, uma entidade autônoma deve buscar atingir o objetivo e, em seguida, manter esse estado de objetivo pelo tempo que o usuário desejar. Covrigaru e Lindsay (1991) referiram-se a tais objetivos como objetivos homeostáticos e afirmaram que os sistemas autônomos tendem a perseguir esses objetivos homeostáticos em vez do que é descrito como objetivos alcançáveis. Os objetivos homeostáticos não terminam quando o sistema está em um estado final; em vez disso, um processo de monitoramento é iniciado com o objetivo de alcançar um estado final se ocorrer uma mudança desse estado. Uma meta atingível é aquela que termina quando o estado de meta final é alcançado. Dito de outra forma, os objetivos homeostáticos operam como um mecanismo administrativo para que um agente possa alcançar e manter seus próprios objetivos alcançáveis. Por exemplo, um agente projetado para monitorar os preços da concorrência receberia a meta alcançável de observar uma mudança de preço e relatar a mudança quando ela ocorresse. A versão homeostática dessa meta exige que o agente monitore indefinidamente os preços da concorrência e, após informar uma mudança de preço, continue monitorando futuras mudanças. Com efeito, o objetivo homeostático atua como um objetivo administrativo em um nível superior, pois garante que o objetivo alcançável seja adequadamente perseguido. Um agente com um objetivo homeostático representa com mais precisão a metáfora de um assistente pessoal. 

		2.2.2 Persistência

 Na literatura de agentes de software, a característica de persistência é interpretada como um programa que está em execução contínua (Chang e Lange 1996), mesmo que essa “execução” signifique que o programa está temporariamente inativo ou em um “estado criogênico” (Bradshaw et al. 1997, p. 385 ). Merriam-Webster (2006) define persistência como “continuação duradoura”. A noção de persistência de uma perspectiva humana é que a entidade ou efeito existirá por um longo tempo em relação ao tempo necessário para atingir um objetivo. A persistência é frequentemente implementada em um agente, dando-lhe pelo menos um thread de execução e implementando uma estrutura de controle que exige que o agente monitore continuamente seu estado, incluindo o status de seu(s) objetivo(s). O encadeamento de execução garante que o agente receba o tempo de processamento necessário e evita que o agente seja interrompido ou retardado por outros processos e encadeamentos em execução no 536 Traci J. Hess et al. mesmo computador. A estrutura de controle garante que o agente possa perseguir objetivos homeostáticos, trabalhando continuamente para atingir o objetivo e manter o estado do objetivo, uma vez alcançado. Permitir que o agente salve seu estado de alguma maneira, digamos, em um arquivo de texto ou banco de dados, pode fornecer um nível mais forte de persistência para o caso de um desligamento de emergência.
 
		2.2.3 Reatividade

	 Na literatura de agentes de software, um programa reativo é definido como aquele que pode reconhecer mudanças em seu ambiente e responder a essas mudanças em tempo hábil (Franklin e Graesser 1996; Wooldridge e Jennings 1995). Essa definição é semelhante à definição de Merriam-Webster (2006) de reatividade como “resposta imediata a um estímulo”, com uma diferença importante: como acontece com a autonomia, um agente é reativo apenas dentro de um ambiente específico e, como Franklin e Graesser enfatizaram, um agente pode deixar de ser um agente quando está fora de seu ambiente. Por exemplo, um agente de software que aprende as preferências musicais de seu usuário reagiria apropriadamente à seleção do usuário de uma gravação clássica, mas não reagiria apropriadamente a um agente de um domínio de manufatura tentando negociar a compra de recursos. 
	A reatividade, como a estamos aplicando aos programas de software, não requer inteligência e é comparável a um cenário de estímulo-resposta. Ser reativo não requer necessariamente inteligência, como indicaria um médico que testasse os reflexos de um joelho humano. Isso não quer dizer que um programa de software que seja inteligente ou capaz de, digamos, interagir com seu ambiente não seja desejável. Acontece que esses recursos extras não são considerados essenciais para o desenvolvimento de um agente autônomo. 
	Em resumo, acreditamos que esta definição e as descrições dos três recursos essenciais fornecem utilidade ao construtor DSS. Para desenvolver um agente, um construtor deve incluir três construções básicas. Se a implementação fosse desenvolvida em Java, ou em um programa orientado a objetos semelhante, a persistência poderia ser obtida executando o agente em uma thread separada, o que poderia implicar no uso da extensão de classe “extends thread” em Java. O objetivo homeostático pode ser alcançado por meio de estruturas de controle, como um loop “while” e declarações “if” aninhadas.

	2.3 Empowerment

 Tendo fornecido uma descrição de um agente autônomo e definido suas características essenciais, agora descrevemos os atributos do agente empowering. As características capacitadoras dos agentes (consulte a Figura 1) são mobilidade, inteligência e interatividade. Lembre-se de que esses recursos não são essenciais para determinar a agência, mas podem ser importantes para tornar um agente útil ou impressionante. Como esses três termos geralmente têm um significado especial quando usados ​​em um contexto de software, agora apontamos as seguintes questões da literatura.
		2.3.1 Mobilidade 
	Em um ambiente de rede, os aplicativos geralmente se comunicam entre si por meio de chamadas de procedimento remoto (RPC) ou pela troca de scripts. O código móvel fornece um meio alternativo de comunicação e é frequentemente associado a agentes de software. Em algumas implementações de agentes, os agentes de software são realmente definidos como código móvel (White 1997). O código móvel difere de um RPC ou da troca de scripts porque, com o código móvel, todo o procedimento “é passado para o servidor remoto, incluindo seu código, dados, estado de execução e itinerário de viagem” (Chang e Lange 1996, p. 1 ). 
	Um agente móvel é um agente que pode ser transportado como código móvel. Um agente que passa mensagens para um local remoto está apenas se comunicando e não exibindo o recurso de mobilidade. Os agentes móveis podem mover-se para vários locais remotos levando consigo um itinerário ou sendo despachados para outro local pelo usuário, um servidor de agente ou outro agente. A persistência e a reatividade permitem que eles concluam suas tarefas quando os sites remotos não estão disponíveis, pois podem esperar em seu local atual até que o site esteja acessível. A mobilidade é uma característica capacitadora do agente porque permite que os agentes usem recursos distribuídos e utilizem os recursos de rede com mais eficiência. O processamento distribuído é facilitado porque os agentes móveis utilizam os recursos de computação do host atual. Os recursos de rede são utilizados com mais eficiência porque os agentes móveis podem mover-se para vários locais em busca de seus objetivos, em vez de enviar inúmeras mensagens e RPCs para cada local de interesse. 

		2.3.2 Inteligência

	 Inteligência é um recurso capacitador que permite a um agente perseguir seus objetivos de forma mais eficiente e habilidosa, com menos assistência do usuário ou projetista. A IBM geralmente descreve a inteligência em relação aos seus próprios agentes como o grau de raciocínio e comportamento aprendido (Gilbert 1997). Imam e Kodratoff (1997) foram um pouco mais longe quando resumiram o esforço de um workshop da American Association for Artificial Intelligence para definir o termo. Eles descreveram um agente inteligente como um “sistema ou máquina que utiliza metodologias computacionais inferenciais ou complexas para executar o conjunto de tarefas de interesse do usuário” (p. 76). A noção de inferência, aprendizado (máquina) ou raciocínio está implícita ou explícita em ambas as definições. 
	As primeiras tentativas na comunidade de inteligência artificial de desenvolver um programa que funcionasse como uma criatura inteligente semelhante à humana, focada na resolução de problemas como uma característica chave para tal programa (Harmon e King 1985). Essa capacidade de resolver problemas era geralmente chamada de inteligência. O que parece ser inteligência em humanos, no entanto, é simplesmente algum mecanismo implementado em um programa (Covrigaru e Lindsay 1991). A inteligência, conforme definida, é uma ferramenta computacional e não é necessária para que um programa de software se comporte como um agente. Esse recurso pode aumentar muito a utilidade de um agente, mas a falta dele não implica em um agente inútil. 
	Agentes com vários tipos de inteligência foram implementados, incluindo aqueles que utilizam algoritmos genéticos (Oliver 1996), aqueles que combinam um conhecimento base e aprendizado por exemplo (Maes 1994) e sistemas com raciocínio baseado em memória (Lashkari et al. 1994). Agentes com habilidades de planejamento em tempo real também foram implementados para facilitar a geração de alternativas em tempo real (Hess et al., 2006), a parte do paradigma de escolha de design de inteligência de Simon (1960) menos apoiada pelo DSS. Os designers podem capacitar seus agentes com essas várias ferramentas de inteligência computacional, melhorando a capacidade de resolução de problemas do agente e exigindo menos interação do usuário com o agente. 

		2.3.3 Interatividade (capacidade comunicativa) 

	A capacidade de se comunicar com usuários e outros agentes é outra característica importante para os agentes de software (Roda et al. 2003; Franklin e Graesser 1996; Wooldridge e Jennings 1995). Agentes que podem dialogar com usuários e outros agentes, e não apenas relatar os resultados de suas ações, são considerados interativos ou comunicativos. Esse tipo de diálogo geralmente é suportado pelo uso de uma linguagem de comunicação do agente (Genesereth e Ketchpel 1997; Petrie 1996). A interatividade não é considerada uma característica fundamental do agente porque um agente pode ser projetado para realizar uma tarefa que não exige que ele mantenha um diálogo com outras pessoas. Por exemplo, um agente que foi projetado para monitorar um site da Web e atualizar um banco de dados quando ocorrem alterações pode precisar apenas relatar os resultados do monitoramento. 
	Embora a comunicação não seja um recurso obrigatório do agente, um agente que pode se comunicar com outros pode aprimorar significativamente suas habilidades. Por exemplo, um agente que pode trocar informações com outros agentes pode ser mais eficiente por meio de cooperação e delegação. Um agente comunicativo ou social poderia economizar uma viagem a vários locais remotos ao se comunicar com um agente que já conhece a informação que está buscando. Além disso, um agente pode ganhar muita eficiência gerando vários novos agentes e instruindo-os a realizar tarefas em paralelo. 
	Ao resumir nossa discussão sobre recursos de capacitação, vale a pena observar que, embora a mobilidade, a inteligência e a interatividade certamente possam aprimorar os recursos de um agente, considerados individualmente, esses recursos não criam um assistente de computação pessoal. Não há autonomia sem as três características essenciais e, assim, o usuário desse código não poderá delegar tarefas a ele. Em vez de, o usuário seria forçado a inicialmente instigar as ações que deseja que o código execute e reinstigar perpetuamente essas ações até que não sejam mais necessárias. Para ilustrar nossa definição de agente autônomo, vários agentes serão descritos. Implementamos agentes dentro de um protótipo de DSS, estabelecendo assim o contexto. As descrições dos agentes individuais destacam os recursos essenciais e fortalecedores que esses agentes exibem, fornecendo uma perspectiva de nível de implementação dos recursos descritos acima.